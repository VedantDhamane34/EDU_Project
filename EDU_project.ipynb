{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VedantDhamane34/EDU_Project/blob/main/EDU_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2igVQM3TlgTl",
        "outputId": "9d784f6d-2d75-4fe6-e6ba-e6afaae0c41f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting verovio\n",
            "  Downloading verovio-4.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading verovio-4.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: verovio, tiktoken\n",
            "Successfully installed tiktoken-0.8.0 verovio-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch accelerate tiktoken verovio torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install pdf2image\n",
        "!apt-get install -y poppler-utils  # Required by pdf2image for PDF rendering"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKMfFSYnHM4E",
        "outputId": "5e372f40-05f6-4343-d0d0-9a2794def87e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (11.0.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.5 [186 kB]\n",
            "Fetched 186 kB in 0s (1,968 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 123630 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.5_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbq0pqK-OATG",
        "outputId": "665463bc-3959-45d2-c416-0b63b3e7ad77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.14-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading PyMuPDF-1.24.14-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.24.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model answers uploading -1\n",
        "# Install the PyMuPDF library\n",
        "\n",
        "# Import necessary libraries\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "# Function to extract text from a PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)  # Open the PDF file\n",
        "    text = \"\"\n",
        "\n",
        "    # Iterate through each page and extract text\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        text += page.get_text()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Upload the PDF file to Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Extract text from the uploaded PDF file\n",
        "pdf_path = next(iter(uploaded))  # Get the file name\n",
        "modelanswerstext = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "# Display the extracted text\n",
        "print(modelanswerstext)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "nMlPDBKuM914",
        "outputId": "1b277cf2-76a4-458d-c5de-1e38378f7087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0b974ca4-d0bb-4782-995f-b8d74c6c3da9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0b974ca4-d0bb-4782-995f-b8d74c6c3da9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model_answer_1.pdf to model_answer_1.pdf\n",
            "Q1: The capital of France is Paris, \n",
            "which is not only the political and \n",
            "administrative center of the \n",
            "country but also its cultural and \n",
            "economic hub.\n",
            "Q2: \"Romeo and Juliet\" is a tragic \n",
            "play written by the English \n",
            "playwright William Shakespeare.\n",
            "Q3: The largest planet in our solar \n",
            "system is Jupiter, a gas giant with \n",
            "a diameter of about 86,881 miles \n",
            "(139,822 kilometers).\n",
            "Q4: The main ingredient in \n",
            "guacamole is avocado, a creamy, \n",
            "nutrient-rich fruit native to \n",
            "Central and South America.\n",
            "Q5: The process by which plants \n",
            "make their food is called \n",
            "photosynthesis, a complex \n",
            "biochemical process.\n",
            "Q6: The Eiffel Tower is a famous \n",
            "landmark in Paris, France, and was \n",
            "completed in 1889.\n",
            "Q7: The Mona Lisa is a famous \n",
            "painting by Leonardo da Vinci, \n",
            "displayed at the Louvre Museum \n",
            "in Paris.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting of model answers to a list -2\n",
        "import re\n",
        "\n",
        "# Input string containing multiple answers (12 answers in this case)\n",
        "input_string = modelanswerstext\n",
        "\n",
        "# Split the input string based on four consecutive zeros followed by one or more digits (e.g., 00000, 000010)\n",
        "answers = re.split(r'(?=Q\\d+)', input_string)\n",
        "\n",
        "# Create a list with enough space for each possible index\n",
        "answers_list = []  # We are using len(answers) to create a list that holds all answers.\n",
        "\n",
        "# Place each answer in the correct index based on the identifier value\n",
        "for answer in answers:\n",
        "    if answer.strip():  # Skip empty strings\n",
        "        match = re.match(r'(Q\\d+):', answer)\n",
        "        if match:\n",
        "            # Remove the question identifier (e.g., \"Q1:\")\n",
        "            answers_list.append(answer[match.end():].strip())\n",
        "\n",
        "# Display the parsed answers\n",
        "for i, answer in enumerate(answers_list, 1):\n",
        "    print(f\"Answer {i}: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RCckGRiLO41O",
        "outputId": "d73eb38c-1a7a-484f-a895-b47e43f9c243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 1: The capital of France is Paris, \n",
            "which is not only the political and \n",
            "administrative center of the \n",
            "country but also its cultural and \n",
            "economic hub.\n",
            "Answer 2: \"Romeo and Juliet\" is a tragic \n",
            "play written by the English \n",
            "playwright William Shakespeare.\n",
            "Answer 3: The largest planet in our solar \n",
            "system is Jupiter, a gas giant with \n",
            "a diameter of about 86,881 miles \n",
            "(139,822 kilometers).\n",
            "Answer 4: The main ingredient in \n",
            "guacamole is avocado, a creamy, \n",
            "nutrient-rich fruit native to \n",
            "Central and South America.\n",
            "Answer 5: The process by which plants \n",
            "make their food is called \n",
            "photosynthesis, a complex \n",
            "biochemical process.\n",
            "Answer 6: The Eiffel Tower is a famous \n",
            "landmark in Paris, France, and was \n",
            "completed in 1889.\n",
            "Answer 7: The Mona Lisa is a famous \n",
            "painting by Leonardo da Vinci, \n",
            "displayed at the Louvre Museum \n",
            "in Paris.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ThbDik7sOy0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#upload student answersheet -3\n",
        "from google.colab import files\n",
        "from pdf2image import convert_from_path\n",
        "import os\n",
        "\n",
        "# Upload the PDF file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Assuming only one PDF is uploaded, get the file name\n",
        "pdf_path = next(iter(uploaded))\n",
        "\n",
        "# Directory to save the images\n",
        "output_dir = '/content/pdf_images'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Method to convert PDF to an array of images and save them as PNG\n",
        "def pdf_to_images_and_save(pdf_path, output_dir):\n",
        "    # Convert the PDF into a list of images (one image per page)\n",
        "    images = convert_from_path(pdf_path)\n",
        "\n",
        "    # List to store the image paths\n",
        "    image_paths = []\n",
        "\n",
        "    # Save each image as PNG and store its path\n",
        "    for i, image in enumerate(images):\n",
        "        image_path = os.path.join(output_dir, f'page_{i+1}.png')\n",
        "        image.save(image_path, 'PNG')\n",
        "        image_paths.append(image_path)\n",
        "\n",
        "    return image_paths\n",
        "\n",
        "# Convert the uploaded PDF to images and save them\n",
        "image_paths = pdf_to_images_and_save(pdf_path, output_dir)\n",
        "\n",
        "# Display the image paths\n",
        "print(\"Saved image paths:\", image_paths)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "M179aNd3HYE3",
        "outputId": "a1d4ac81-672f-465a-e6e3-feec2cd2bbaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-585ef972-b396-49a2-a6b7-f02aea524e0e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-585ef972-b396-49a2-a6b7-f02aea524e0e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving student_ans1.pdf to student_ans1.pdf\n",
            "Saved image paths: ['/content/pdf_images/page_1.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('ucaslcl/GOT-OCR2_0', trust_remote_code=True, revision=\"main\")\n",
        "model = AutoModel.from_pretrained('ucaslcl/GOT-OCR2_0', trust_remote_code=True, revision=\"main\", low_cpu_mem_usage=True, use_safetensors=True, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "# Set the model to evaluation mode and move it to GPU (CUDA)\n",
        "model = model.eval().cuda()"
      ],
      "metadata": {
        "id": "tMcNYaxUl7HZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_file = '/content/Screenshot 2024-11-15 124000.png'  # Replace 'xxx.jpg' with your image file path\n",
        "\n",
        "# Perform plain text OCR on GPU using the .chat() method\n",
        "res = model.chat(tokenizer, image_file, ocr_type='ocr')\n",
        "\n",
        "# Print the OCR result\n",
        "print(\"OCR Output:\", res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGHgYZwol-UU",
        "outputId": "ae995c31-3f9e-4d8d-89ee-6316e509cb0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
            "`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OCR Output: 00002: The largest planet in our solar system is Jupiter, a gas giant with a diameter of about 86881 miles( 139822 kilometers)  00000: The capital of France is Paris, which is not only the political and admin is tatu ve center of the county but aldo it s cult u al and ecOnO mic hub.  00001: “ Romeo and Juliet\" is a tragic play written by the English play w sight william Shakesp e are.  00003: The main ingredient in guacamole is avoca do, a creamy,  nut sent- rich fruit native to Central and South Amexica.  00006: The Mona Lisa is a famous painting by Leon a do da Vinci,  displayed at the Louv ne Museum in Paris,  00007: water b oll at 1 OO c under standard atmO phe rie c phe s sive.  00009: The Great wall of China is One Of the most famous hist or vic al sites in the world,  00004: The pro ced by which plants make the is food is called photo y the d is, a complex biochemical pro ceed 000010: The Amazon Rain to west is the largest rain to west in the world, located in South America.  000011: Shakesp e are' s play\" Hamlet\" is a tragedy about Prince Hamlet of Denmark 000012: The Pacific Ocean is the largest and deepest ocean. On Earth, covering more than 63 million square miles 00005: The Eft tel Tower is a famous landmark in Paris, France,  and was completed in 1889 00008: Mount Eves est is the highest mountain in the world,  Standing at 8848 mete d( 29029 feet)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ocr on images  -4\n",
        "# Assuming 'images' is an array of image file paths\n",
        "\n",
        "images  = image_paths\n",
        "# Initialize an empty string to store the OCR results\n",
        "final_ocr_result = \"\"\n",
        "\n",
        "# Iterate through the array of images\n",
        "for image_file in images:\n",
        "    # Perform plain text OCR using the .chat() method\n",
        "    res = model.chat(tokenizer, image_file, ocr_type='ocr')\n",
        "\n",
        "    # Append the OCR result of the current image to the final result\n",
        "    final_ocr_result += res + \"\\n\"  # Adding a newline between each image's result for separation\n",
        "\n",
        "# Print the final concatenated OCR result\n",
        "print(\"Final OCR Output:\", final_ocr_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5jWLN5JHt24",
        "outputId": "2daf7335-3387-42fb-b4df-2c953fd683cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final OCR Output: Q3: Jupiter is the biggest planet. It's a gas \n",
            "giant with a diameter of about 86,881 miles \n",
            "(139,822 kilometers). \n",
            "Q1: France's capital is paris. It's not just the \n",
            "political and administrative center but also the \n",
            "cultural centre of the country. \n",
            "Q2: \"Romeo and Juliet\" is a tragic play written \n",
            "by William Shakespeare. It's about two young \n",
            "lovers whose families are feuding. \n",
            "Q4: The main ingredient in vacamole is avocado. \n",
            "It's a creamy and nutrient-rich fruit that \n",
            "comes from central and South America. \n",
            "Q7: The Mona Lisa is a famous painting by \n",
            "Leonardo da Vinci. It's displayed at the Louvre \n",
            "Museum in Paris. \n",
            "Q5: Photosynthesis is the process by which plants \n",
            "make their food. It involves converting light \n",
            "energy into chemical energy using sunlight, carbon \n",
            "dioxide, and water. \n",
            "Q6: The Eiffel Tower is a famous landmark in \n",
            "Paris. It was completed in 1889 and was initially \n",
            "criticized but is now a symbol of France.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "\n",
        "# Load the pre-trained model for sentence embeddings\n",
        "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Input string containing multiple answers\n",
        "input_string = final_ocr_result\n",
        "\n",
        "# Model answers (provided)\n",
        "model_answers = answers_list\n",
        "print(\"Model Answers:\", model_answers)\n",
        "\n",
        "# Split the input string based on 'Q' followed by one or more digits\n",
        "answers = re.split(r'(?=Q\\d+:)', input_string)\n",
        "\n",
        "# Create a list to store student answers, matching the model answers' size\n",
        "student_answers_list = [\"\"] * len(model_answers)\n",
        "\n",
        "# Extract student answers and place in the correct index\n",
        "for answer in answers:\n",
        "    if answer.strip():  # Skip empty or invalid segments\n",
        "        match = re.match(r'(Q\\d+):', answer)\n",
        "        if match:\n",
        "            # Extract the question number (e.g., \"Q1\", \"Q2\")\n",
        "            question_number = int(match.group(1)[1:])  # Get the number part after \"Q\"\n",
        "            # Ensure the index is within the bounds of model answers\n",
        "            if 1 <= question_number <= len(model_answers):\n",
        "                # Remove the question identifier (e.g., \"Q1:\")\n",
        "                student_answers_list[question_number - 1] = answer[match.end():].strip()\n",
        "\n",
        "print(\"Student Answers:\", student_answers_list)\n",
        "\n",
        "# Encode both student and model answers into embeddings\n",
        "student_embeddings = model.encode(student_answers_list, convert_to_tensor=True)\n",
        "model_embeddings = model.encode(model_answers, convert_to_tensor=True)\n",
        "\n",
        "# Compute similarity scores for each answer\n",
        "cos = nn.CosineSimilarity(dim=1)\n",
        "similarities = []\n",
        "\n",
        "for student_answer, model_answer, student_embedding, model_embedding in zip(student_answers_list, model_answers, student_embeddings, model_embeddings):\n",
        "    # Check if model answer is present in the student's answer\n",
        "    if model_answer.lower() in student_answer.lower():\n",
        "        similarity = 1.0  # Full marks (similarity = 100%)\n",
        "    else:\n",
        "        similarity = cos(student_embedding.unsqueeze(0), model_embedding.unsqueeze(0)).item()\n",
        "    similarities.append(similarity)\n",
        "\n",
        "# Calculate overall score out of 100\n",
        "average_similarity = sum(similarities) / len(similarities)\n",
        "overall_score = round(average_similarity * 100, 2)\n",
        "\n",
        "# Print individual similarities and overall score\n",
        "for i, (student, model, similarity) in enumerate(zip(student_answers_list, model_answers, similarities)):\n",
        "    similarity_percentage = round(similarity * 100, 2)\n",
        "    print(f\"Q{i+1}:\")\n",
        "    print(f\"Student Answer: {student}\")\n",
        "    print(f\"Model Answer: {model}\")\n",
        "    print(f\"Similarity: {similarity_percentage}%\\n\")\n",
        "\n",
        "print(f\"Overall Score: {overall_score}/100\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Isfga6pCnF0f",
        "outputId": "522b0c83-6c13-421c-f886-a18c55b56161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Answers: ['The capital of France is Paris, \\nwhich is not only the political and \\nadministrative center of the \\ncountry but also its cultural and \\neconomic hub.', '\"Romeo and Juliet\" is a tragic \\nplay written by the English \\nplaywright William Shakespeare.', 'The largest planet in our solar \\nsystem is Jupiter, a gas giant with \\na diameter of about 86,881 miles \\n(139,822 kilometers).', 'The main ingredient in \\nguacamole is avocado, a creamy, \\nnutrient-rich fruit native to \\nCentral and South America.', 'The process by which plants \\nmake their food is called \\nphotosynthesis, a complex \\nbiochemical process.', 'The Eiffel Tower is a famous \\nlandmark in Paris, France, and was \\ncompleted in 1889.', 'The Mona Lisa is a famous \\npainting by Leonardo da Vinci, \\ndisplayed at the Louvre Museum \\nin Paris.']\n",
            "Student Answers: [\"France's capital is paris. It's not just the \\npolitical and administrative center but also the \\ncultural centre of the country.\", '\"Romeo and Juliet\" is a tragic play written \\nby William Shakespeare. It\\'s about two young \\nlovers whose families are feuding.', \"Jupiter is the biggest planet. It's a gas \\ngiant with a diameter of about 86,881 miles \\n(139,822 kilometers).\", \"The main ingredient in vacamole is avocado. \\nIt's a creamy and nutrient-rich fruit that \\ncomes from central and South America.\", 'Photosynthesis is the process by which plants \\nmake their food. It involves converting light \\nenergy into chemical energy using sunlight, carbon \\ndioxide, and water.', 'The Eiffel Tower is a famous landmark in \\nParis. It was completed in 1889 and was initially \\ncriticized but is now a symbol of France.', \"The Mona Lisa is a famous painting by \\nLeonardo da Vinci. It's displayed at the Louvre \\nMuseum in Paris.\"]\n",
            "Q1:\n",
            "Student Answer: France's capital is paris. It's not just the \n",
            "political and administrative center but also the \n",
            "cultural centre of the country.\n",
            "Model Answer: The capital of France is Paris, \n",
            "which is not only the political and \n",
            "administrative center of the \n",
            "country but also its cultural and \n",
            "economic hub.\n",
            "Similarity: 93.23%\n",
            "\n",
            "Q2:\n",
            "Student Answer: \"Romeo and Juliet\" is a tragic play written \n",
            "by William Shakespeare. It's about two young \n",
            "lovers whose families are feuding.\n",
            "Model Answer: \"Romeo and Juliet\" is a tragic \n",
            "play written by the English \n",
            "playwright William Shakespeare.\n",
            "Similarity: 86.38%\n",
            "\n",
            "Q3:\n",
            "Student Answer: Jupiter is the biggest planet. It's a gas \n",
            "giant with a diameter of about 86,881 miles \n",
            "(139,822 kilometers).\n",
            "Model Answer: The largest planet in our solar \n",
            "system is Jupiter, a gas giant with \n",
            "a diameter of about 86,881 miles \n",
            "(139,822 kilometers).\n",
            "Similarity: 92.79%\n",
            "\n",
            "Q4:\n",
            "Student Answer: The main ingredient in vacamole is avocado. \n",
            "It's a creamy and nutrient-rich fruit that \n",
            "comes from central and South America.\n",
            "Model Answer: The main ingredient in \n",
            "guacamole is avocado, a creamy, \n",
            "nutrient-rich fruit native to \n",
            "Central and South America.\n",
            "Similarity: 58.29%\n",
            "\n",
            "Q5:\n",
            "Student Answer: Photosynthesis is the process by which plants \n",
            "make their food. It involves converting light \n",
            "energy into chemical energy using sunlight, carbon \n",
            "dioxide, and water.\n",
            "Model Answer: The process by which plants \n",
            "make their food is called \n",
            "photosynthesis, a complex \n",
            "biochemical process.\n",
            "Similarity: 87.9%\n",
            "\n",
            "Q6:\n",
            "Student Answer: The Eiffel Tower is a famous landmark in \n",
            "Paris. It was completed in 1889 and was initially \n",
            "criticized but is now a symbol of France.\n",
            "Model Answer: The Eiffel Tower is a famous \n",
            "landmark in Paris, France, and was \n",
            "completed in 1889.\n",
            "Similarity: 94.65%\n",
            "\n",
            "Q7:\n",
            "Student Answer: The Mona Lisa is a famous painting by \n",
            "Leonardo da Vinci. It's displayed at the Louvre \n",
            "Museum in Paris.\n",
            "Model Answer: The Mona Lisa is a famous \n",
            "painting by Leonardo da Vinci, \n",
            "displayed at the Louvre Museum \n",
            "in Paris.\n",
            "Similarity: 98.89%\n",
            "\n",
            "Overall Score: 87.45/100\n"
          ]
        }
      ]
    }
  ]
}